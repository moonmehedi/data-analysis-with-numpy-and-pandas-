{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4acf141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef47ce2",
   "metadata": {},
   "source": [
    "# Assignment 1: pd.Concat\n",
    "\n",
    "Combine the 2014 and 2015 data you wrote out in the last section into a single dataframe. \n",
    "\n",
    "Then delete the transactions DataFrame (there is a handy base Python keyword for this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca22035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to read in transactions data if you need to re-create CSV/Excel files from section 8 \n",
    "# NOTE: You won't have the extra columns we created but it won't matter for this assignment\n",
    "\n",
    "# transactions = pd.read_csv(\"../retail/transactions.csv\", parse_dates=[\"date\"])\n",
    "\n",
    "# Excel\n",
    "# with pd.ExcelWriter(\"DataForChandler.xlsx\") as writer:\n",
    "#     for year in range(2013, 2018):\n",
    "#         transactions.loc[transactions[\"date\"].dt.year == year].to_excel(\n",
    "#             writer, sheet_name=str(year)\n",
    "#         )\n",
    "        \n",
    "# CSV        \n",
    "# for year in range(2013, 2018):\n",
    "#     transactions.loc[transactions[\"date\"].dt.year == year].to_csv(\n",
    "#         f\"transactions_{year}.csv\"\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491f5d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV\n",
    "\n",
    "# Read in two csv files and concatenate them into a single DataFrame\n",
    "\n",
    "transactions = pd.concat(\n",
    "    (pd.read_csv(\"transactions_2014.csv\"), \n",
    "     pd.read_csv(\"transactions_2015.csv\")),\n",
    ").drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97b9719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excel \n",
    "\n",
    "# Read in two Excel sheets and concatenate them into a single DataFrame\n",
    "\n",
    "transactions = pd.concat(\n",
    "    pd.read_excel(\"DataForChandler.xlsx\", sheet_name=[1, 2]),  #  specify sheets 1 and 2 to grab correct years\n",
    "    ignore_index=True  #  specify to create consecutive index across sheets\n",
    ").drop([\"Unnamed: 0\"], axis=1)  #  drop index col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09193e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect head of df\n",
    "\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406c111f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect tail of df\n",
    "\n",
    "transactions.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917b0035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete DataFrame from memory\n",
    "\n",
    "del transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0320d0",
   "metadata": {},
   "source": [
    "# Assignment 2: Joins\n",
    "\n",
    "Can you join retail.csv with stores.csv? You'll need to read both files in.\n",
    "\n",
    "Once you have that, plot:\n",
    "* Total sales by city, \n",
    "* The sum of sales by “type” over time,\n",
    "* A stacked bar chart with average daily sales by type by month, with “type” as the “stacks”. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f155f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "retail = pd.read_csv(\"../retail/retail_2016_2017.csv\", parse_dates=[\"date\"])\n",
    "stores = pd.read_csv(\"../retail/stores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00974b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "retail.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b662a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f030c5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join stores to retail on 'store_nbr' column\n",
    "\n",
    "retail_stores = retail.merge(stores,\n",
    "                             how=\"inner\",\n",
    "                             left_on=\"store_nbr\",\n",
    "                             right_on=\"store_nbr\"\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5906dd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at head of DataFrame to confirm Join as expected\n",
    "retail_stores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d8d2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at info of joined DataFrame\n",
    "\n",
    "retail_stores.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae76fc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group joined DF by city, calculate sales by city, create bar plot from highest to lowest\n",
    "\n",
    "(retail_stores\n",
    " .groupby([\"city\"])\n",
    " .agg({\"sales\": \"sum\"})\n",
    " .sort_values(by=\"sales\", ascending=False\n",
    ").plot.bar())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183d7db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pivot table with date in index and type as column, cells are sum sales for type/day\n",
    "# then create a line plot with increased figure size\n",
    "\n",
    "retail_stores.pivot_table(\n",
    "    index=[\"date\"], \n",
    "    columns=\"type\", \n",
    "    values=\"sales\", \n",
    "    aggfunc=\"sum\"\n",
    ").plot(figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5aa3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pivot table with type in index and month as column, cells are sum sales for type/day\n",
    "# Note: You may have chosen row as month and type as column, that's fine too!\n",
    "\n",
    "retail_stores.pivot_table(\n",
    "    index=\"type\", \n",
    "    columns=retail_stores[\"date\"].dt.month, \n",
    "    values=\"sales\", \n",
    "    aggfunc=\"mean\"\n",
    ").T.plot.bar(stacked=True).legend(bbox_to_anchor=(1, 1)) # T, or transpose flips the DataFrame by its axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633f5f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete DataFrames used in join\n",
    "\n",
    "del [retail, stores]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
